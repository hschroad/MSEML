{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import initializers\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import json\n",
    "\n",
    "fcc_elements = [\"Ag\", \"Al\", \"Au\", \"Cu\", \"Ir\", \"Ni\", \"Pb\", \"Pd\", \"Pt\", \"Rh\", \"Th\", \"Yb\"]\n",
    "bcc_elements = [\"Ba\", \"Cr\", \"Cs\", \"Eu\", \"Fe\", \"Li\", \"Mn\", \"Mo\", \"Na\", \"Nb\", \"Rb\", \"Ta\", \"V\", \"W\" ]\n",
    "hcp_elements = [\"Be\", \"Ca\", \"Cd\", \"Co\", \"Dy\", \"Er\", \"Gd\", \"Hf\", \"Ho\", \"Lu\", \"Mg\", \"Re\", \n",
    "                \"Ru\", \"Sc\", \"Tb\", \"Ti\", \"Tl\", \"Tm\", \"Y\", \"Zn\", \"Zr\"]\n",
    "others = [\"Si\", \"Ge\"] # \"Si\" and \"Ge\" are Face-centered diamond-cubic;\n",
    "\n",
    "elements = fcc_elements + others + bcc_elements + hcp_elements\n",
    "\n",
    "querable_mendeleev = [\"atomic_number\", \"atomic_volume\", \"boiling_point\", \"en_ghosh\",  \"evaporation_heat\", \"heat_of_formation\",\n",
    "                     \"lattice_constant\", \"melting_point\", \"specific_heat\"]\n",
    "querable_pymatgen = [\"atomic_mass\", \"atomic_radius\", \"electrical_resistivity\",\"molar_volume\", \"bulk_modulus\", \"youngs_modulus\",\n",
    "                     \"average_ionic_radius\", \"density_of_solid\", \"coefficient_of_linear_thermal_expansion\"]\n",
    "querable_values = querable_mendeleev + querable_pymatgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "\n",
    "with open(\"all_values.csv\", \"r\") as f:\n",
    "    all_values = json.load(f)\n",
    "\n",
    "# Pandas Dataframe\n",
    "df = pd.DataFrame(all_values, columns=querable_values)\n",
    "\n",
    "# We will patch some of the values that are not available in the datasets.\n",
    "\n",
    "# Value for the CTE of Cesium\n",
    "index_Cs = df.index[df['atomic_number'] == 55]\n",
    "df.iloc[index_Cs, df.columns.get_loc(\"coefficient_of_linear_thermal_expansion\")] = 0.000097 \n",
    "# Value from: David R. Lide (ed), CRC Handbook of Chemistry and Physics, 84th Edition. CRC Press. Boca Raton, Florida, 2003\n",
    "\n",
    "# Value for the CTE of Rubidium\n",
    "index_Rb = df.index[df['atomic_number'] == 37]\n",
    "df.iloc[index_Rb, df.columns.get_loc(\"coefficient_of_linear_thermal_expansion\")] = 0.000090 \n",
    "# Value from: https://www.azom.com/article.aspx?ArticleID=1834\n",
    "\n",
    "# Value for the Evaporation Heat of Ruthenium\n",
    "index_Ru = df.index[df['atomic_number'] == 44]\n",
    "df.iloc[index_Ru, df.columns.get_loc(\"evaporation_heat\")] = 595 # kJ/mol \n",
    "# Value from: https://www.webelements.com/ruthenium/thermochemistry.html\n",
    "\n",
    "# Value for the Bulk Modulus of Zirconium\n",
    "index_Zr = df.index[df['atomic_number'] == 40]\n",
    "df.iloc[index_Zr, df.columns.get_loc(\"bulk_modulus\")] = 94 # GPa \n",
    "# Value from: https://materialsproject.org/materials/mp-131/\n",
    "\n",
    "# Value for the Bulk Modulus of Germanium\n",
    "index_Ge = df.index[df['atomic_number'] == 32]\n",
    "df.iloc[index_Ge, df.columns.get_loc(\"bulk_modulus\")] = 77.2 # GPa \n",
    "# Value from: https://www.crystran.co.uk/optical-materials/germanium-ge\n",
    "\n",
    "# Value for the Young's Modulus of Germanium\n",
    "index_Ge = df.index[df['atomic_number'] == 32]\n",
    "df.iloc[index_Ge, df.columns.get_loc(\"youngs_modulus\")] = 102.7 # GPa \n",
    "# Value from: https://www.crystran.co.uk/optical-materials/germanium-ge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atomic_number</th>\n",
       "      <th>atomic_volume</th>\n",
       "      <th>boiling_point</th>\n",
       "      <th>en_ghosh</th>\n",
       "      <th>evaporation_heat</th>\n",
       "      <th>heat_of_formation</th>\n",
       "      <th>lattice_constant</th>\n",
       "      <th>melting_point</th>\n",
       "      <th>specific_heat</th>\n",
       "      <th>atomic_mass</th>\n",
       "      <th>atomic_radius</th>\n",
       "      <th>electrical_resistivity</th>\n",
       "      <th>molar_volume</th>\n",
       "      <th>bulk_modulus</th>\n",
       "      <th>average_ionic_radius</th>\n",
       "      <th>density_of_solid</th>\n",
       "      <th>coefficient_of_linear_thermal_expansion</th>\n",
       "      <th>youngs_modulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47</td>\n",
       "      <td>10.30</td>\n",
       "      <td>2485.0</td>\n",
       "      <td>0.147217</td>\n",
       "      <td>254.1</td>\n",
       "      <td>284.9</td>\n",
       "      <td>4.09</td>\n",
       "      <td>1235.10</td>\n",
       "      <td>0.237</td>\n",
       "      <td>107.868200</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.630000e-08</td>\n",
       "      <td>10.27</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.086667</td>\n",
       "      <td>10490.0</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>10.00</td>\n",
       "      <td>2740.0</td>\n",
       "      <td>0.150078</td>\n",
       "      <td>284.1</td>\n",
       "      <td>330.9</td>\n",
       "      <td>4.05</td>\n",
       "      <td>933.50</td>\n",
       "      <td>0.900</td>\n",
       "      <td>26.981539</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.700000e-08</td>\n",
       "      <td>10.00</td>\n",
       "      <td>76.0</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>2700.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>10.20</td>\n",
       "      <td>3080.0</td>\n",
       "      <td>0.261370</td>\n",
       "      <td>340.0</td>\n",
       "      <td>368.2</td>\n",
       "      <td>4.08</td>\n",
       "      <td>1337.58</td>\n",
       "      <td>0.129</td>\n",
       "      <td>196.966569</td>\n",
       "      <td>1.35</td>\n",
       "      <td>2.200000e-08</td>\n",
       "      <td>10.21</td>\n",
       "      <td>220.0</td>\n",
       "      <td>1.070000</td>\n",
       "      <td>19300.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>7.10</td>\n",
       "      <td>2840.0</td>\n",
       "      <td>0.151172</td>\n",
       "      <td>304.6</td>\n",
       "      <td>337.4</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1356.60</td>\n",
       "      <td>0.385</td>\n",
       "      <td>63.546000</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.720000e-08</td>\n",
       "      <td>7.11</td>\n",
       "      <td>140.0</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>8920.0</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77</td>\n",
       "      <td>8.54</td>\n",
       "      <td>4403.0</td>\n",
       "      <td>0.251060</td>\n",
       "      <td>604.0</td>\n",
       "      <td>669.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2683.00</td>\n",
       "      <td>0.133</td>\n",
       "      <td>192.217000</td>\n",
       "      <td>1.35</td>\n",
       "      <td>4.700000e-08</td>\n",
       "      <td>8.52</td>\n",
       "      <td>320.0</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>22650.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>528.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   atomic_number  atomic_volume  boiling_point  en_ghosh  evaporation_heat  \\\n",
       "0             47          10.30         2485.0  0.147217             254.1   \n",
       "1             13          10.00         2740.0  0.150078             284.1   \n",
       "2             79          10.20         3080.0  0.261370             340.0   \n",
       "3             29           7.10         2840.0  0.151172             304.6   \n",
       "4             77           8.54         4403.0  0.251060             604.0   \n",
       "\n",
       "   heat_of_formation  lattice_constant  melting_point  specific_heat  \\\n",
       "0              284.9              4.09        1235.10          0.237   \n",
       "1              330.9              4.05         933.50          0.900   \n",
       "2              368.2              4.08        1337.58          0.129   \n",
       "3              337.4              3.61        1356.60          0.385   \n",
       "4              669.0              3.84        2683.00          0.133   \n",
       "\n",
       "   atomic_mass  atomic_radius  electrical_resistivity  molar_volume  \\\n",
       "0   107.868200           1.60            1.630000e-08         10.27   \n",
       "1    26.981539           1.25            2.700000e-08         10.00   \n",
       "2   196.966569           1.35            2.200000e-08         10.21   \n",
       "3    63.546000           1.35            1.720000e-08          7.11   \n",
       "4   192.217000           1.35            4.700000e-08          8.52   \n",
       "\n",
       "   bulk_modulus  average_ionic_radius  density_of_solid  \\\n",
       "0         100.0              1.086667           10490.0   \n",
       "1          76.0              0.675000            2700.0   \n",
       "2         220.0              1.070000           19300.0   \n",
       "3         140.0              0.820000            8920.0   \n",
       "4         320.0              0.765000           22650.0   \n",
       "\n",
       "   coefficient_of_linear_thermal_expansion  youngs_modulus  \n",
       "0                                 0.000019            83.0  \n",
       "1                                 0.000023            70.0  \n",
       "2                                 0.000014            78.0  \n",
       "3                                 0.000017           130.0  \n",
       "4                                 0.000006           528.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First, we'll create the heatmap again\n",
    "all_labels = df['youngs_modulus'].tolist()\n",
    "\n",
    "# make a list of all the inputs\n",
    "all_inputs = df.values.tolist()\n",
    "\n",
    "# Make a list of the young's modulus column so that we can append it to the end\n",
    "youngs_modulus = list(df['youngs_modulus'])\n",
    "\n",
    "# Drop young's modulus column\n",
    "df = df.drop('youngs_modulus', axis = 1)\n",
    "\n",
    "# Create a new young's modulus column, this time at the end\n",
    "df[\"youngs_modulus\"] = youngs_modulus\n",
    "\n",
    "# create a list of all the labels\n",
    "labels = df.columns.tolist()\n",
    "\n",
    "# Check that it's at the end\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, I will make lists of all the variables I would like to optmize\n",
    "# The loop can then be modified to loop through any of these lists\n",
    "\n",
    "# These are the values for the validation split\n",
    "# The original value was 0.10\n",
    "val_list = [0.12, 0.11, 0.10, 0.09, 0.08, 0.07, 0.06, 0.05, 0.04]\n",
    "\n",
    "# These are the values that will be tested for the rms learning rate\n",
    "# The original values used was 0.002\n",
    "rms_list = [0.005, 0.003, 0.0025, 0.002, 0.0015, 0.001, 0.0005, 0.0002, 0.0001]\n",
    "\n",
    "# These are the values that will be tested for the number of nodes for the first layer\n",
    "# The original value was 32\n",
    "nodes_1 = list(range(10,33))\n",
    "\n",
    "# These are the values that will be tested for the number of nodes for the second layer\n",
    "# The original value was 64\n",
    "nodes_2 = list(range(10,75))\n",
    "\n",
    "# I will also test how many layers is optimal, but this doesn't require a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMS Learning Rate Test\n",
    "\n",
    "# How long the loop will be\n",
    "the_end = 30\n",
    "\n",
    "# How long the loop will be for rms\n",
    "rms_end = len(rms_list)\n",
    "\n",
    "# Create an empty list to which we'll add our final values\n",
    "rms_values = []\n",
    "\n",
    "# Open a file where will write our output to\n",
    "v_file = open(\"rms_data_shuffled.csv\", \"w\")\n",
    "\n",
    "# Counting variables\n",
    "i = 0\n",
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00538: early stopping\n",
      "The current iteration is \n",
      " 0\n",
      "0.005 16.169 41.465\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00722: early stopping\n",
      "The current iteration is \n",
      " 1\n",
      "0.003 13.0 37.084\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00879: early stopping\n",
      "The current iteration is \n",
      " 2\n",
      "0.0025 11.132 27.243\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00942: early stopping\n",
      "The current iteration is \n",
      " 3\n",
      "0.002 11.098 18.42\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 01122: early stopping\n",
      "The current iteration is \n",
      " 4\n",
      "0.0015 11.366 14.077\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 01567: early stopping\n",
      "The current iteration is \n",
      " 5\n",
      "0.001 10.298 24.152\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 02709: early stopping\n",
      "The current iteration is \n",
      " 6\n",
      "0.0005 9.748 30.811\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 06437: early stopping\n",
      "The current iteration is \n",
      " 7\n",
      "0.0002 8.975 35.962\n",
      "The current iteration is \n",
      " 8\n",
      "0.0001 14.943 35.605\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00538: early stopping\n",
      "The current iteration is \n",
      " 0\n",
      "0.005 16.169 41.465\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00722: early stopping\n",
      "The current iteration is \n",
      " 1\n",
      "0.003 13.0 37.084\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00777: early stopping\n",
      "The current iteration is \n",
      " 2\n",
      "0.0025 11.132 27.243\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00950: early stopping\n",
      "The current iteration is \n",
      " 3\n",
      "0.002 11.098 18.42\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 01090: early stopping\n",
      "The current iteration is \n",
      " 4\n",
      "0.0015 11.366 14.077\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 01636: early stopping\n",
      "The current iteration is \n",
      " 5\n",
      "0.001 10.298 24.152\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 02701: early stopping\n",
      "The current iteration is \n",
      " 6\n",
      "0.0005 9.748 30.811\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 06613: early stopping\n",
      "The current iteration is \n",
      " 7\n",
      "0.0002 8.975 35.962\n",
      "The current iteration is \n",
      " 8\n",
      "0.0001 14.943 35.605\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00538: early stopping\n",
      "The current iteration is \n",
      " 0\n",
      "0.005 16.169 41.465\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00722: early stopping\n",
      "The current iteration is \n",
      " 1\n",
      "0.003 13.0 37.084\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00827: early stopping\n",
      "The current iteration is \n",
      " 2\n",
      "0.0025 11.132 27.243\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00956: early stopping\n",
      "The current iteration is \n",
      " 3\n",
      "0.002 11.098 18.42\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 01060: early stopping\n",
      "The current iteration is \n",
      " 4\n",
      "0.0015 11.366 14.077\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 01622: early stopping\n",
      "The current iteration is \n",
      " 5\n",
      "0.001 10.298 24.152\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 02688: early stopping\n",
      "The current iteration is \n",
      " 6\n",
      "0.0005 9.748 30.811\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 06639: early stopping\n",
      "The current iteration is \n",
      " 7\n",
      "0.0002 8.975 35.962\n",
      "Current Epoch: 1694\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f1617394d36f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Training Values (Properties), Training Labels (Known Young's Moduli)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         history = model.fit(train_values, train_labels, batch_size = train_values.shape[0], \n\u001b[0;32m---> 74\u001b[0;31m                         epochs = EPOCHS, verbose = False, validation_split = 0.10, callbacks=[mae_es, PrintEpNum()]) \n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Validation Test\n",
    "while j < the_end:\n",
    "    i = 0\n",
    "    while i < rms_end:\n",
    "        # open file\n",
    "        v_file = open(\"rms_data.csv\", \"a\")\n",
    "   \n",
    "        # Reassign the dataframe\n",
    "        sf = df\n",
    "    \n",
    "        # Drop youngs modulus\n",
    "        sf = df.drop('youngs_modulus', axis = 1)\n",
    "\n",
    "        all_values = [list(sf.iloc[x]) for x in range(len(all_values))]\n",
    "\n",
    "        # SETS\n",
    "\n",
    "        # List of lists are turned into Numpy arrays to facilitate calculations in steps to follow (Normalization).\n",
    "        all_values = np.array(all_values, dtype = float) \n",
    "        #print(\"Shape of Values:\", all_values.shape)\n",
    "        all_labels = np.array(all_labels, dtype = float)\n",
    "        #print(\"Shape of Labels:\", all_labels.shape)\n",
    "\n",
    "        # Uncomment the line below to shuffle the dataset (we do not do this here to ensure consistent results for every run)\n",
    "        # order = np.argsort(np.random.random(all_labels.shape)) # This numpy argsort returns the indexes that would be used to shuffle a list\n",
    "        order = np.arange(49)\n",
    "        all_values = all_values[order]\n",
    "        all_labels = all_labels[order]\n",
    "\n",
    "        # Training Set\n",
    "        train_labels = all_labels[:44]\n",
    "        train_values = all_values[:44]\n",
    "\n",
    "        # Testing Set\n",
    "        test_labels = all_labels[-5:]\n",
    "        test_values = all_values[-5:]\n",
    "\n",
    "        # NORMALIZATION\n",
    "        mean = np.mean(train_values, axis = 0) # mean\n",
    "        std = np.std(train_values, axis = 0) # standard deviation\n",
    "\n",
    "        train_values = (train_values - mean) / std # input scaling\n",
    "        test_values = (test_values - mean) / std # input scaling\n",
    "\n",
    "        # DEFINITION OF THE MODEL\n",
    "\n",
    "        # The weights of our neural network will be initialized in a random manner, using a seed allows for reproducibility\n",
    "        kernel_init = initializers.RandomNormal(seed=0)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, activation='relu', input_shape=(train_values.shape[1], ), kernel_initializer=kernel_init))\n",
    "        model.add(Dense(64, activation='relu', kernel_initializer=kernel_init))\n",
    "        model.add(Dense(1, kernel_initializer=kernel_init))\n",
    "\n",
    "        # DEFINITION OF THE OPTIMIZER\n",
    "\n",
    "        optimizer = tf.train.RMSPropOptimizer(rms_list[i]) # Root Mean Squared Propagation\n",
    "\n",
    "        # This line matches the optimizer to the model and states which metrics will evaluate the model's accuracy\n",
    "        model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "        # model.summary()\n",
    "\n",
    "        class PrintEpNum(keras.callbacks.Callback): # This is a function for the Epoch Counter\n",
    "            def on_epoch_end(self, epoch, logs):\n",
    "                sys.stdout.flush()\n",
    "                sys.stdout.write(\"Current Epoch: \" + str(epoch+1) + '\\r') # Updates current Epoch Number\n",
    "\n",
    "        mae_es= keras.callbacks.EarlyStopping(monitor='mean_absolute_error', patience=10, verbose=1, mode='auto', restore_best_weights=True)    \n",
    "        EPOCHS = 10000 # Number of EPOCHS\n",
    "\n",
    "        # HISTORY Object which contains how the model learned\n",
    "        # Training Values (Properties), Training Labels (Known Young's Moduli)\n",
    "        history = model.fit(train_values, train_labels, batch_size = train_values.shape[0], \n",
    "                        epochs = EPOCHS, verbose = False, validation_split = 0.10, callbacks=[mae_es, PrintEpNum()]) \n",
    "\n",
    "\n",
    "        [loss_train, mae_train] = model.evaluate(train_values, train_labels, verbose=0)\n",
    "        [loss_test, mae_test] = model.evaluate(test_values, test_labels, verbose=0)\n",
    "\n",
    "        # Here is where we append the dropped variable, mae test, and train values\n",
    "        rms_values.append([rms_list[i],round(mae_train, 3), round(mae_test, 3)])\n",
    "    \n",
    "        # Display the current iteration\n",
    "        print(\"The current iteration is \\n\" ,i)\n",
    "\n",
    "        # write to a file\n",
    "        v_file.write(\" \".join(str(x) for x in rms_values[i]))\n",
    "        v_file.write(\"\\n\")\n",
    "    \n",
    "        # Display the same information being written to the file\n",
    "        print(\" \".join(str(x) for x in rms_values[i]))\n",
    "\n",
    "        # counting variable\n",
    "        i = i + 1\n",
    "    \n",
    "        # Close the file    \n",
    "        v_file.close()\n",
    "    \n",
    "    # Counting variable\n",
    "    j = j + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMS Learning Rate Test\n",
    "\n",
    "# How long the loop will be\n",
    "the_end = 30\n",
    "\n",
    "# How long the loop will be for rms\n",
    "rms_end = len(rms_list)\n",
    "\n",
    "# Create an empty list to which we'll add our final values\n",
    "rms_values = []\n",
    "\n",
    "# Open a file where will write our output to\n",
    "v_file = open(\"rms_data_shuffled.csv\", \"w\")\n",
    "\n",
    "# Counting variables\n",
    "i = 0\n",
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00286: early stopping\n",
      "The current iteration of j is \n",
      " 0\n",
      "0.005 46.997 166.214\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00046: early stopping\n",
      "The current iteration of j is \n",
      " 1\n",
      "0.005 46.997 166.214\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00042: early stopping\n",
      "The current iteration of j is \n",
      " 2\n",
      "0.005 46.997 166.214\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00049: early stopping\n",
      "The current iteration of j is \n",
      " 3\n",
      "0.005 46.997 166.214\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-da0caa45cc56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Training Values (Properties), Training Labels (Known Young's Moduli)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         history = model.fit(train_values, train_labels, batch_size = train_values.shape[0], \n\u001b[0;32m---> 74\u001b[0;31m                         epochs = EPOCHS, verbose = False, validation_split = 0.10, callbacks=[mae_es, PrintEpNum()]) \n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 199\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1319\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m/apps/share64/debian7/anaconda/anaconda-6/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1352\u001b[0;31m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m   \u001b[0;31m# The threshold to run garbage collection to delete dead tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Validation Test\n",
    "while i < rms_end:\n",
    "    j = 0\n",
    "    while j < the_end:\n",
    "        # open file\n",
    "        v_file = open(\"rms_data_shuffled.csv\", \"a\")\n",
    "   \n",
    "        # Reassign the dataframe\n",
    "        sf = df\n",
    "    \n",
    "        # Drop youngs modulus\n",
    "        sf = df.drop('youngs_modulus', axis = 1)\n",
    "\n",
    "        all_values = [list(sf.iloc[x]) for x in range(len(all_values))]\n",
    "\n",
    "        # SETS\n",
    "\n",
    "        # List of lists are turned into Numpy arrays to facilitate calculations in steps to follow (Normalization).\n",
    "        all_values = np.array(all_values, dtype = float) \n",
    "        #print(\"Shape of Values:\", all_values.shape)\n",
    "        all_labels = np.array(all_labels, dtype = float)\n",
    "        #print(\"Shape of Labels:\", all_labels.shape)\n",
    "\n",
    "        # Uncomment the line below to shuffle the dataset (we do not do this here to ensure consistent results for every run)\n",
    "        order = np.argsort(np.random.random(all_labels.shape)) # This numpy argsort returns the indexes that would be used to shuffle a list\n",
    "        #order = np.arange(49)\n",
    "        all_values = all_values[order]\n",
    "        all_labels = all_labels[order]\n",
    "\n",
    "        # Training Set\n",
    "        train_labels = all_labels[:44]\n",
    "        train_values = all_values[:44]\n",
    "\n",
    "        # Testing Set\n",
    "        test_labels = all_labels[-5:]\n",
    "        test_values = all_values[-5:]\n",
    "\n",
    "        # NORMALIZATION\n",
    "        mean = np.mean(train_values, axis = 0) # mean\n",
    "        std = np.std(train_values, axis = 0) # standard deviation\n",
    "\n",
    "        train_values = (train_values - mean) / std # input scaling\n",
    "        test_values = (test_values - mean) / std # input scaling\n",
    "\n",
    "        # DEFINITION OF THE MODEL\n",
    "\n",
    "        # The weights of our neural network will be initialized in a random manner, using a seed allows for reproducibility\n",
    "        kernel_init = initializers.RandomNormal(seed=0)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, activation='relu', input_shape=(train_values.shape[1], ), kernel_initializer=kernel_init))\n",
    "        model.add(Dense(64, activation='relu', kernel_initializer=kernel_init))\n",
    "        model.add(Dense(1, kernel_initializer=kernel_init))\n",
    "\n",
    "        # DEFINITION OF THE OPTIMIZER\n",
    "\n",
    "        optimizer = tf.train.RMSPropOptimizer(rms_list[i]) # Root Mean Squared Propagation\n",
    "\n",
    "        # This line matches the optimizer to the model and states which metrics will evaluate the model's accuracy\n",
    "        model.compile(loss='mse', optimizer=optimizer, metrics=['mae'])\n",
    "        # model.summary()\n",
    "\n",
    "        class PrintEpNum(keras.callbacks.Callback): # This is a function for the Epoch Counter\n",
    "            def on_epoch_end(self, epoch, logs):\n",
    "                sys.stdout.flush()\n",
    "                sys.stdout.write(\"Current Epoch: \" + str(epoch+1) + '\\r') # Updates current Epoch Number\n",
    "\n",
    "        mae_es= keras.callbacks.EarlyStopping(monitor='mean_absolute_error', patience=10, verbose=1, mode='auto', restore_best_weights=True)    \n",
    "        EPOCHS = 10000 # Number of EPOCHS\n",
    "\n",
    "        # HISTORY Object which contains how the model learned\n",
    "        # Training Values (Properties), Training Labels (Known Young's Moduli)\n",
    "        history = model.fit(train_values, train_labels, batch_size = train_values.shape[0], \n",
    "                        epochs = EPOCHS, verbose = False, validation_split = 0.10, callbacks=[mae_es, PrintEpNum()]) \n",
    "\n",
    "\n",
    "        [loss_train, mae_train] = model.evaluate(train_values, train_labels, verbose=0)\n",
    "        [loss_test, mae_test] = model.evaluate(test_values, test_labels, verbose=0)\n",
    "\n",
    "        # Here is where we append the dropped variable, mae test, and train values\n",
    "        rms_values.append([rms_list[i],round(mae_train, 3), round(mae_test, 3)])\n",
    "    \n",
    "        # Display the current iteration\n",
    "        print(\"The current iteration of j is \\n\" ,j)\n",
    "\n",
    "        # write to a file\n",
    "        v_file.write(\" \".join(str(x) for x in rms_values[i]))\n",
    "        v_file.write(\"\\n\")\n",
    "    \n",
    "        # Display the same information being written to the file\n",
    "        print(\" \".join(str(x) for x in rms_values[i]))\n",
    "\n",
    "        # Close the file    \n",
    "        v_file.close()\n",
    "        \n",
    "        j = j + 1\n",
    "\n",
    "# Display the current iteration\n",
    "print(\"The current iteration of i is \\n\" ,i)\n",
    "i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
